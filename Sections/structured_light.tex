\documentclass[class=article, crop=false]{standalone}

\begin{document}
Spatial information provided by a camera is inherently 2D, whereas 3D information is needed for motion tracking. Without affixing markers with known geometric properties, multiple cameras are needed for depth perception. Finding accurate and robust correspondences of points in these multiple camera views is therefore required. Structured light techniques offer a solution to the correspondence problem by replacing a camera with a light source that projects some user-defined pattern onto the scene. Finding correspondences between views and hence 3D information becomes a matter of finding the intersection of a ray projected from a viewing camera centre with the projected light plane (Figure 1). Given a calibration between light source and detector, 3D surface coordinates can be found through triangulation, and a map of the object surface can be formed. For comprehensive reviews on structured light techniques, see \cite{Geng2011} and \cite{Salvi2010}.
\par
Algorithms associated with obtaining the 3D surface map are dependent on the type of surface illumination. These illumination techniques can be categorized as either being ‘single-shot’ or ‘multi-shot’. The latter requires the integration of multiple structured light patterns projected sequentially, while the former can produce a surface map from a single pattern projection. Intuitively, single-shot techniques appear better suited for motion tracking applications, as they provide better sampling rates. On the other hand, multi-shot techniques may offer more accurate and reliable measurements, given the sequential illuminations can be projected and captured in a short enough time for any motion that occurs in the FOV. 
\par
Single-shot structured light techniques make use of chromatic light, light with spatially varying intensity or projected grid patterns such that full 3D information of a scene can be extracted from a single frame. The `rainbow' system developed by Geng \parencite*{JasonGeng1996} projects patterns with spatially varying wavelength, with simple triangulation being possible for each pixel given a known system baseline. A similar approach by Carrihill and Hummel \parencite*{Carrihill1985} used a spatially varying greyscale profile. These methods, while allowing for dense surface reconstruction, suffer from high sensitivity to noise and require a smooth imaging surface with little colour variation.
\par
Periodic patterns can also be projected to obtain dense feature maps, with depth information being encoded into the phase of the illumination. Such methods are not as susceptible to changes in the illuminating pattern caused by the scene. There are various ways to extract phase information; phase-shift interferometry (PSI) \parencite{ISI:A1974U657500060,Huang1999}, Fourier transform profilometry (FTP) \parencite{Takeda:83,Yue20071170} and wavelet transform profilometry (WTP) \parencite{Gdeisat2006482,Fernandez2010}. Both FTP and WTP are single-shot techniques, while PSI requires multiple shots (at least three) unless the phase-shifted, sinusoidal fringe patterns are multiplexed, as in \cite{Huang1999}.
\par
Examples of different structured light patterns are shown in Figure 2. Other single-shot illumination strategies involve projecting coded stripes \parencite{Boyer1987,Forster2007,Zhang2002}, or 2D grid patterns \parencite{Petriu2000,Pages2006,Albitar2006}. Multi-shot techniques, capable of providing high resolution 3D information for large number of projections, can offer resistance against noise. Projecting successive binary patterns is the traditional multi-shot approach \parencite{Posdamer1982}, with the addition of colour encoding \parencite{Caspi1998} or PSI \parencite{Huang2006} helping to reduce the number of projected patterns.
\par
In the context of motion tracking, a structured light approach for quantifying movement of rodent heads for preclinical PET was recently reported by \cite{Miranda2017}. A stereo system, the Ensenso N10 (Ensenso GmbH, Freiburg im Breisgau, Germany), which consisted of an IR sensitive camera and IR random point pattern projector was used. A surface map of the rat head was obtained at a frequency of 31 Hz, and the motion between captures was calculated using iterative closest point (ICP).
\par 
The use of IR structured light for motion tracking was also demonstrated by Olesen et al. \parencite*{Olesen2012} for human heads in a medical imaging scanner. They reported errors of 0.09$^{\circ}$ and 0.24 mm for a system which used successive IR sinusoid projections and PSI to measure motion of the head in a Siemens High Resolution Research Tomograph (HRRT) PET scanner. Similar to an MRI scanner, the HRRT has a narrow bore, meaning that the motion tracking system had to be compact for in or near-bore use. Preliminary results for an MR-compatible version of this system have also been shown \parencite{Olesen2015a}. The rate at which the 3D point clouds could be streamed was 8.4 Hz. For clinical applications, the use of IR patterns would be beneficial, as shining visible light onto the patient's face during the scan would negatively affect comfort.
\par



	
\end{document}