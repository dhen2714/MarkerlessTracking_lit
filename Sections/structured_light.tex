\documentclass[class=article, crop=false]{standalone}

\begin{document}
Spatial information provided by a camera is inherently 2D, whereas 3D information is needed for motion tracking. Without affixing markers with known geometric properties, multiple cameras are needed for depth perception. Finding accurate and robust correspondences of points in these multiple camera views is therefore required. Structured light techniques offer a solution to the correspondence problem by replacing a camera with a light source that projects some user-defined pattern onto the scene. Finding correspondences between views and hence 3D information becomes a matter of finding the intersection of a ray projected from a viewing camera centre with the projected light plane (Figure 1). Given a calibration between light source and detector, 3D surface coordinates can be found through triangulation, and a map of the object surface can be formed. For comprehensive reviews on structured light techniques, see \cite{Geng2011} and \cite{Salvi2010}.
\par
Algorithms associated with obtaining the 3D surface map are dependent on the type of surface illumination. These illumination techniques can be categorized as either being ‘single-shot’ or ‘multi-shot’. The latter requires the integration of multiple structured light patterns projected sequentially, while the former can produce a surface map from a single pattern projection. Intuitively, single-shot techniques appear better suited for motion tracking applications, as they provide better sampling rates. On the other hand, multi-shot techniques may offer more accurate and reliable measurements, given the sequential illuminations can be projected and captured in a short enough time for any motion that occurs in the FOV. 
\par
Single-shot structured light techniques make use of chromatic light, light with spatially varying intensity or projected grid patterns such that full 3D information of a scene can be extracted from a single frame. The `rainbow' system developed by Geng \parencite*{JasonGeng1996} projects patterns with spatially varying wavelength, with simple triangulation being possible for each pixel given a known system baseline. A similar approach by Carrihill and Hummel \parencite*{Carrihill1985} used a spatially varying greyscale profile. These methods, while allowing for dense surface reconstruction, suffer from high sensitivity to noise and require a smooth imaging surface with little colour variation.
\par
Periodic patterns can also be projected to obtain dense feature maps, with depth information being encoded into the phase of the illumination. Such methods are not as susceptible to changes in the illuminating pattern caused by the scene. There are various ways to extract phase information; phase-shift interferometry (PSI) \parencite{ISI:A1974U657500060,Huang1999}, Fourier transform profilometry (FTP) \parencite{Takeda:83,Yue20071170} and wavelet transform profilometry (WTP) \parencite{Gdeisat2006482,Fernandez2010}. Both FTP and WTP are single-shot techniques, while PSI requires multiple shots (at least three) unless the phase-shifted, sinusoidal fringe patterns are multiplexed, as in \cite{Huang1999}.
\par
Examples of different structured light patterns are shown in Figure 2. Other single-shot illumination strategies involve projecting coded stripes, or 2D grid patterns. Multi-shot techniques, capable of providing high resolution 3D information for large number of projections, can offer resistance against noise. Projecting successive binary patterns is the traditional multi-shot approach \parencite{Posdamer1982}, with the addition of colour encoding \parencite{Caspi1998} or PSI \parencite{Huang2006} helping to reduce the number of projected patterns.
\par
A structured light system 



	
\end{document}