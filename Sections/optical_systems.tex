\documentclass[class=article, crop=false]{standalone}

\begin{document}
Optical systems make use of one more cameras operating at visible wavelengths to track and quantify head movements. Tracking is achieved by detecting object features from frame to frame. These features can include active or reflective fiducial markers, which have been explored as viable components of head tracking systems in MRI. Without the attachment of markers, head tracking becomes more difficult, as distinctive object features must be detected in scenes for which \textit{a priori} information may not be available. The detection of features should also be quite consistent and robust, invariant to changes in scene illumination or content. Outside of medical imaging, markerless tracking of the head, or head pose estimation has a wide range of applications including augmented reality, human-machine interfacing and studying human behaviour. For reviews, see \cite{Murphy-Chutorian2009} and \cite{Lepetit2005}.
\par
Optical tracking systems are either monocular (one-camera) or multi-camera. Depth information cannot be extracted from a single camera alone. For this reason, monocular systems incorporate pixel data into some 3D model, \textit{a priori} or otherwise. Early techniques involved extraction of edges in the image, which could then be either be matched to successive frames with an algorithms similar to RAPiD, or matched to edges in an object model. Both approaches are capable of 6 DoF tracking. Individual pixel information is used in optical flow algorithms, and interest point-based methods, which work similarly to edge-based methods in that motion information is derived from correspondences across successive frames, as well as correspondences between the initial frame and an object model \parencite{Ravela1995}.
\par  
The inability of monocular systems to extract 3D information from individual frames means by themselves they are highly susceptible to error accumulation, or drift. The critical importance placed on the accuracy of object models is also problematic for head tracking in MRI, as current algorithms generally require that the entire head be in the camera FoV \parencite{Jeni2017a,Jourabloo2016,Zhu2016,Dong2016,Gu2006}. As mentioned in the previous section, the presence of the head coil means an unobstructed view of the whole face is unlikely. Current markerless monocular systems are also not capable of sub-millimetre and sub-degree accuracy in characterisation of rigid body motion, and thus appear unsuited for application in MRI.
\par
Multi-camera systems are capable of obtaining 3D information from a single frame, provided that the cameras comprising the system are calibrated. Stereo triangulation (Figure \ref{triangulation}) is the calculation of the 3D coordinates of a landmark detected by two cameras, given the pixel coordinates of the feature in both cameras. The accuracy of the 3D measurement is dependent on the noise of the two cameras and their resolution. Adding additional cameras may prove more robust to noise, as well as to feature occlusion. Without markers, matching features or knowing what pixels in one view correspond to another is known as the correspondence problem.

\begin{figure}
	\centering
	\includegraphics*[scale=0.75]{triangulation}
	\caption{Stereo triangulation. Given pixel coordinates y and y$'$ of the same scene point, the 3D position Q of the point can be found through triangulation.}
	\label{triangulation}
\end{figure}

\par 
Similarly to monocular systems, markerless tracking with multi-camera systems begins with the extraction of features such as edges. Popular feature detection algorithms such as SIFT \parencite{Lowe2004} and SURF \parencite{Bay2008} are able to localise keypoint features of various sizes by sampling `scale-space', which, for SIFT, involves the successive application of Gaussian kernels of varying width. SIFT and SURF  also include a framework for describing features, such that correspondences can be found across temporally and geometrically varying views. Once matched, these features or clusters of features can be fit to some model of the face, or triangulated and tracked individually.
\par 
Markerless systems that have been reported for human PET include \cite{Anishchenko2015,Gao2007} and \cite{Ma2008}. The former two studies used algorithms designed to detect specific facial features (such as eye corners or tip of the nose), whereas the latter used the more general approach of tracking SIFT features. \cite{Anishchenko2015} compared their system to magnetic sensors, with the average mismatch being 1.6 mm. Cameras were placed out of bore for all of these systems.
\par
For small-animal PET, Kyme et al. \parencite*{Kyme2014} used a four-camera setup to track SIFT features (Figure \ref{rathead}a). The 3D location and descriptor for each triangulated landmark was stored in a database such that detected SIFT keypoints in later frames could be used to calculate the pose of the head, in an approach similar to ones used in simultaneous localisation and mapping (SLAM) in mobile robotics \parencite{Se2002,Se2005}. Sub-millimetre accuracy was reported for the tracking of a taxidermy rat head. For a live rat, it was found that many of the detected features lay on parts of the head that moved non-rigidly, adversely affecting motion estimates. To amplify the number of features in rigidly moving parts of the head, the authors proposed the use of additional ink-based facial markings (Figure \ref{rathead}b). While this approach may not be strictly markerless, the ink-based features move with the surface being imaged, thus potentially providing a way of detecting or measuring non-rigid motion which would not be possible with a traditional, single marker based approach.

\begin{figure}
	\centering
	\includegraphics*[scale=0.63]{rathead}
	\caption{SIFT features detection for a rat head. a) SIFT features (red boxes) detected on a taxidermal rat head matched (white lines) to a different view. b) SIFT features detected on a live rat. In order to amplify number of features detected, ink markings were added to the rat head. Left picture without markings, right with markings. Images taken from \parencite{Kyme2014}.}
	\label{rathead}
\end{figure}

\par 
Preliminary testing of method used by Kyme et al. \parencite*{Kyme2014} on humans has been reported \parencite{Kyme2016,Kyme2013}. In \cite{Kyme2016}, tracking of the head was done in the bore of an MRI scanner, without markers and with the application of an ink-based stamp on the forehead. The accuracy of these methods is highly dependent on the ability to extract enough SIFT features on non-rigidly moving parts of the head. The ability to place cameras inside the head coil may be beneficial for this reason, as close-up shots of the face would provide more detail for feature extraction.
\par 
In order to be adapted for MRI, optical systems still require some refinement. With monocular systems being ruled out due to their lack of accuracy, stereo or multi-camera approaches are left as an option. The methodology presented by Kyme et al. \parencite*{Kyme2014} for small-animal imaging appears readily adaptable for use with humans \parencite{Kyme2016,Kyme2013}. Although sub-millimetre accuracy was reported for the tracking of a taxidermal rat head, it is unclear if this level of accuracy is possible for the tracking of a human head.

\end{document}